<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Project Atomic</title>
  <subtitle>Tag: Event</subtitle>
  <id>http://www.projectatomic.io/blog/</id>
  <link href="http://www.projectatomic.io/blog/"/>
  <link href="http://www.projectatomic.io/blog/tag/event.xml" rel="self"/>
  <updated>2019-11-21T00:00:00+00:00</updated>
  <author>
    <name>Project Atomic. Sponsored by Red Hat, Inc.</name>
  </author>
  <entry>
    <title>Docker Brno -- Summer is OVER</title>
    <link rel="alternate" href="http://www.projectatomic.io/blog/2016/10/docker-brno-meetup-20160914/"/>
    <id>http://www.projectatomic.io/blog/2016/10/docker-brno-meetup-20160914/</id>
    <published>2016-10-11T12:00:20+00:00</published>
    <updated>2021-10-07T14:03:16+00:00</updated>
    <author>
      <name>Brian (bex) Exelbierd</name>
    </author>
    <content type="html">&lt;p&gt;Summer is over and school is back in session.  These events mark a
change of seasons, a change in lifestyle, and a return to the
&lt;a href="https://www.meetup.com/Docker-Brno/"&gt;meetups&lt;/a&gt; of Docker Brno. &lt;a href="https://www.twitter.com/TomasTomec"&gt;Tomáš
Tomeček&lt;/a&gt; guided 45 of us through
presentations by three speakers as well as a news and updates presentation.&lt;/p&gt;

&lt;p&gt;&lt;img alt="Tomáš Tomeček" width="400" height="300" src="/images/docker-brno-2016-09/ttomecek.jpg?1633620578" /&gt;&lt;/p&gt;

&lt;p&gt;Tomas started us off with a news and updates presentation about recent changes in Docker
(&lt;a href="https://tomastomecek.github.io/brno-docker-meetup-september-2016/#/"&gt;Slides&lt;/a&gt;).
He briefly covered a lot of the features in the latest releases of docker,
versions 1.12.0 and 1.12.1.&lt;/p&gt;

&lt;p&gt;These versions include the new orchestration components bundled into
the daemon. The addition of the components is particularly controversial
and has caused some people to wonder why they are part of docker-engine.&lt;/p&gt;

&lt;p&gt;Along with the orchestration components, a new abstraction called the
service API was added along with load balancing using IPVS in Linux
Kernel.  Additional features include a plugin API, a new HEALTHCHECK
instruction, and the &lt;code&gt;--live-restore&lt;/code&gt; daemon flag that allows for
auto-restarting of your containers.&lt;/p&gt;

&lt;p&gt;&lt;img alt="Joseph Karasek" width="400" height="300" src="/images/docker-brno-2016-09/jkarasek.jpg?1633620578" /&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href="https://www.twitter.com/Pepe_CZ"&gt;Josef Karásek&lt;/a&gt; presented &amp;ldquo;Rolling Down
the Upgrade River doesn&amp;rsquo;t need to be a White Water Experience.&amp;rdquo; This
demonstration of rolling updates used a Java application running in
docker containers on &lt;a href="http://www.openshift.org"&gt;OpenShift Origin&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;The demo was a &amp;ldquo;canary-style&amp;rdquo; rolling upgrade,
allowing an application to be upgraded in-place, on a live service, with
no interruption for client sessions. While the demo used a monolithic
application, many of the &lt;a href="https://12factor.net/"&gt;Twelve-Factor App&lt;/a&gt;
principles were satisfied.&lt;/p&gt;

&lt;p&gt;In both a show of demo-bravery and zero-to-hero magic, he started his
demo with a clean install of OpenShift Origin.  This was done using the
new &lt;code&gt;oc cluster up&lt;/code&gt; command which started a local single node OpenShift
environment on his laptop.  His secondary goal was to show how he could
go from nothing to a fully launched Java application in less that 15
minutes, including build time and downloads.&lt;/p&gt;

&lt;p&gt;To build the demo application he performed the following actions in the
web console and with the CLI.  He alternated between them to show off
OpenShift during the build process.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Created a project to hold a git forge.  OpenShift lives behind a NAT
by default, so he needed a git forge that could send a webhook to the
rest of OpenShift.  This project contains one container that provides a
&lt;a href="https://gogs.io/"&gt;Gogs - Go Git Service&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Created a second project to hold the actual application.  Into this
project he loaded:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;A Java application based on a JBoss EAP Quickstart example.
The application is built using maven and is able to create and
greet users and store session IDs in a replicated cache. The
greeting page displays the cached session key information and
reports what node is serving it. The session key was stored in
a cache replicated over all EAP nodes. The application ran on a
tiny cluster of two EAP servers (on a laptop!).&lt;/li&gt;
&lt;li&gt;A Postgres database to store user information.&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Configured Image Streams and other administrative components of
OpenShift so that new builds can be automatically triggered and
deployed.  This would normally be done by the operations team and
not the developer.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Added the URL for the webhook to Gogs.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Started the application and let it build.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;While the build was finishing, he talked about how
there are models for using OpenShift that include full
&lt;a href="https://blog.openshift.com/cicd-with-openshift/"&gt;CI/CD&lt;/a&gt; systems, like
Jenkins. These models allow code changes to be built, tested, merged
and deployed automatically. Today, he changed the code and merged it
by hand because he was on his laptop and had memory constraints.&lt;/p&gt;

&lt;p&gt;Then it was demo breaking time! Karásek scaled the application to two replicas
and showed how a specific pod was assigned to serve it.  A &amp;ldquo;pod&amp;rdquo; is a
Kubernetes abstraction that represents one or more related containers.
The containers are managed as a single group for administrative
purposes, including replication. In this example, each pod consists
of one Java application container. Once we were convinced that the HAProxy
router used by OpenShift would not allow us to be served by any other
pod, he deleted the pod. The other pod was able to pick up the session
without a user visible failure because of the auto-spawn capabilities
of OpenShift and the session ID cache.&lt;/p&gt;

&lt;p&gt;Next, it was time for a code change. A quick &lt;code&gt;git clone&lt;/code&gt; later and the
code was modified and pushed to the Gogs service.  Less than a second
later OpenShift reacted to the git webhook notification and kicked
of a new build of the code.  Using the web console and &lt;code&gt;oc get pod&lt;/code&gt;,
we watched the builds progress. When complete, they seamlessly and
invisibly replaced the original pods with zero downtime.&lt;/p&gt;

&lt;p&gt;This demonstration provided insight into how an existing application can
be migrated to containers to gain scale-out and management features from
an orchestrator like OpenShift Origin in a way that preserves all of
the hard-won existing functionality.  Take a look at the &lt;a href="https://github.com/josefkarasek/eap-rolling-update"&gt;demo script
and code&lt;/a&gt; and try
it yourself.&lt;/p&gt;

&lt;p&gt;We took breaks between every talk and enjoyed the fine facilities provided
by &lt;a href="http://www.jobsatkiwi.com/"&gt;kiwi.com&lt;/a&gt;.  They arranged for the use
of their wine cellar for the meetup and a large supply of beverages and
food for the attendees.&lt;/p&gt;

&lt;p&gt;&lt;img alt="Vadim Rutkovsky" width="400" height="300" src="/images/docker-brno-2016-09/vladim.jpg?1633620578" /&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href="https://www.twitter.com/vrutkovs"&gt;Vadim Rutkovsky&lt;/a&gt; was next with his
presentation, &lt;q&gt;Ansible Container: Look mom, no Dockerfile!&lt;/q&gt;
(&lt;a href="https://vrutkovs.github.io/dockerbrno-ansible-container"&gt;Slides&lt;/a&gt;)
His need for a new way to build containers was driven by his use of
&lt;a href="http://grafana.org/"&gt;grafana&lt;/a&gt;.  He started with a container from
DockerHub, but quickly hit some limitations that would mean he needed
a custom built version.&lt;/p&gt;

&lt;p&gt;This should be easy to do as the Dockerfiles are online next to
the containers. Unfortunately, the Dockerfile in question, while
successfully able to build a container, was crazy-pants and not easy to
maintain or modify. In particular its handling of plugins was not
elegant.&lt;/p&gt;

&lt;p&gt;This got him thinking about traditional application
installment concepts and he decided to use &lt;a href="https://www.github.com/ansible/ansible-container"&gt;Ansible
Container&lt;/a&gt;.  Ansible
Container has ability to build docker images and orchestrate containers
using only Ansible playbooks + shell + docker-compose. It allows the
container builder to leverage the power of Ansible features like vars,
templates and roles.&lt;/p&gt;

&lt;p&gt;Getting started is easy thanks to the &lt;code&gt;ansible-container init&lt;/code&gt; command.
This generates the basic files of:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;main.yml&lt;/code&gt;: that describes the images&lt;/li&gt;
&lt;li&gt;&lt;code&gt;container.yml&lt;/code&gt;: that describes orchestration&lt;/li&gt;
&lt;li&gt;&lt;code&gt;requirements.txt&lt;/code&gt;: which can load additional Ansible modules,
if required&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;A huge win came with the &lt;code&gt;main.yml&lt;/code&gt; file structure because the container
could be built using traditional application and system installation
idioms.&lt;/p&gt;

&lt;p&gt;A build using Ansible Container creates a &amp;ldquo;builder image&amp;rdquo;
which allows building and deploying one or more images.&lt;br&gt;
Ansible Container can then launch the container using &lt;code&gt;docker-compose&lt;/code&gt;,
 or it can create a playbook and ship it to Kubernetes and OpenShift.&lt;/p&gt;

&lt;p&gt;The project is fairly new and the next round of features
will include build caching, detached execution, custom
volumes and build variables, and rkt and OCI support.  Full
&lt;a href="https://docs.ansible.com/ansible-container"&gt;documentation&lt;/a&gt; is online
as well as an active community in #ansible-container on Freenode.&lt;/p&gt;

&lt;p&gt;&lt;img alt="Tomas Kral" width="400" height="300" src="/images/docker-brno-2016-09/tkral.jpg?1633620578" /&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href="https://www.twitter.com/kadel"&gt;Tomáš Král&lt;/a&gt;
presented the final talk of the evening, &lt;q&gt;Kompose:
from your local machine to the cloud with one command.&lt;/q&gt;
(&lt;a href="https://github.com/kadel/kompose-demo/blob/master/slides/docker_meetup_20160915.pdf"&gt;Slides&lt;/a&gt;)
&lt;a href="https://github.com/skippbox/kompose"&gt;Kompose&lt;/a&gt; can convert a Docker Compose
file into a full Kubernetes or OpenShift configuration.  It is a golang
open source project supported by Skippbox, Google and Red Hat.&lt;/p&gt;

&lt;p&gt;Kral&amp;rsquo;s demo used the golang guestbook application which he had decomposed
into two containerized services.  First he started the application
just using a pair of &lt;code&gt;docker run&lt;/code&gt; commands that started each service.
Next he showed and used a Docker Compose file that was equivalent to
the same pair of commands.  Kompose showed up at this point and with one
command allowed us to deploy our application to a local Minikube cluster.&lt;/p&gt;

&lt;p&gt;As a final demo step, he made a live deployment to &lt;a href="https://console.preview.openshift.com"&gt;OpenShift 3 Online
(dev-preview)&lt;/a&gt; to show how to
go from a Docker Compose file on your local machine to a live production
deployment in the cloud.&lt;/p&gt;

&lt;p&gt;Kompose allows you to easily move from a development environment using
Docker Compose or an application delivered with a distributed application
bundle (DAB) file to a production quality environment based on Kubernetes
and OpenShift. The output of Kompose allows you to quickly bootstrap
to the rich Kubernetes and OpenShift environments with a standard
configuration that can then be tuned and configured.  Download the &lt;a href="https://github.com/kadel/kompose-demo"&gt;demo
code and script&lt;/a&gt; and try it out.&lt;/p&gt;

&lt;p&gt;This meetup was a fantastic event showing of some really cool technology.
I want to thank our speakers, attendees and sponsors for an making this
such an awesome event.  I personally walked away motivated to play
with both Ansible Container and Kompose to solve some challenges in
my tech-life.&lt;/p&gt;

&lt;p&gt;The meetup was made possible through the generosity of our sponsors:
&lt;a href="http://www.jobsatkiwi.com/"&gt;kiwi.com&lt;/a&gt;, who provided space and
refreshments, and &lt;a href="https://community.redhat.com"&gt;Red Hat&lt;/a&gt;, who provided
administrative support and funding.&lt;/p&gt;

&lt;p&gt;Our &lt;a href="https://www.meetup.com/Docker-Brno/events/234091097/"&gt;next meetup&lt;/a&gt;
will be on 1 December 2016.  We are looking for speakers and hope
you&amp;rsquo;ll contact us at &lt;a href="https://twitter.com/DockerBrno"&gt;@DockerBrno&lt;/a&gt; or
on our &lt;a href="https://www.meetup.com/Docker-Brno"&gt;meetup page&lt;/a&gt;.  If you&amp;rsquo;re not local to Brno and
are interested in talking, contact us too.  We may able to invite and
sponsor you.&lt;/p&gt;
</content>
  </entry>
  <entry>
    <title>Docker Brno&amp;mdash;Back in the Saddle Again</title>
    <link rel="alternate" href="http://www.projectatomic.io/blog/2016/06/docker-brno-meetup-20160615/"/>
    <id>http://www.projectatomic.io/blog/2016/06/docker-brno-meetup-20160615/</id>
    <published>2016-06-21T18:40:20+00:00</published>
    <updated>2021-10-07T14:03:16+00:00</updated>
    <author>
      <name>Brian (bex) Exelbierd</name>
    </author>
    <content type="html">&lt;p&gt;On the 15th of June, over 60 brave souls gathered together and in defiance of an absolutely gorgeous summer day, talked about containers. Four speakers presented a very different set of talks covering all areas of containers from development to management to deployment.&lt;/p&gt;

&lt;p&gt;Jiří Sedláček, an agile QA specialist and developer at &lt;a href="https://www.wandera.com/"&gt;Wandera&lt;/a&gt;, presented &amp;ldquo;Development and Deployment Simplification with Containers&amp;rdquo; (&lt;a href="http://www.projectatomic.io/images/docker_brno_20160615.pdf"&gt;slides&lt;/a&gt;). At a previous company, he and the team implemented a docker-driven development environment that helped change the operational philosophy from the bottom up.&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;

&lt;p&gt;&lt;img alt="picture of Jiří Sedláček" width="800" height="533" src="/images/jiri.jpg?1633620578" /&gt;&lt;/p&gt;

&lt;p&gt;After covering some background material on the benefits of containers over virtual machines for some applications, Jiří started the bulk of his talk by making it clear that his team wasn&amp;rsquo;t doing &amp;ldquo;rocket science.&amp;rdquo; &lt;em&gt;(Note to self: I wonder if anyone at the European Space Agency is using containers&amp;hellip;)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;The development teams initially considered docker, with the goals of unifying the development environment for developers spread across multiple workstation operating systems and making bootstrapping the application environment easier. The environment was a RESTful API-based web service using Apache Tomcat, MongoDB, Apache ActiveMQ, MariaDB, and other data-warehousing technologies. Not rocket science, as he noted, but difficult for a developer to cleanly and easily configure and bring up without becoming &amp;ldquo;grump cat.&amp;rdquo;&lt;/p&gt;

&lt;p&gt;Initially operations was resistant to the move to containers, as they were concerned about the maturity of the technology and deployment issues. These were resolved two ways: first, the container build pipeline was automated and logical base images were built for each stage reducing management overhead; second, a configuration management tool, &lt;a href="http://github.com/markround/tiller"&gt;Tiller&lt;/a&gt; was implemented. The configuration tool was a big win because it solved complexity problems for the developers and eased the transition of the Ops team from traditional management methods to containers and put them on the road to orchestration. His slides include ten big learnings from this project and I encourage you to give them a read.&lt;/p&gt;

&lt;p&gt;We took a break and when we resumed, we heard from &lt;a href="https://twitter.com/janbleha"&gt;Jan Bleha&lt;/a&gt; from &lt;a href="http://kiwi.com"&gt;Kiwi.com&lt;/a&gt;, one of our sponsors. Kiwi.com provided us with 128 (a significant number!) units of our favorite cold carbonated beverages to help us stay ready to ask questions and network. Jan also talked about several other local meetup groups that Kiwi.com helps to sponsor, including meetings around Python, Golang, JS, Reactive, and more. They are also organizing a Czech Language-intensive Python weekend in July. If you&amp;rsquo;ve never visited Brno, I strongly encourage you visit. There is a &lt;strong&gt;huge&lt;/strong&gt; open source and technology community here and I guarantee you will find a group of really smart people with whom to interact.&lt;/p&gt;

&lt;p&gt;Our next two speakers both presented lightning talks. We are using this format to encourage everyone to speak at future meetings (&lt;em&gt;hint, hint&lt;/em&gt;) because now length isn&amp;rsquo;t a challenge!&lt;/p&gt;

&lt;p&gt;&lt;img alt="picture of sen" src="https://raw.githubusercontent.com/TomasTomecek/june-2016-docker-meetup-talk/master/img/sen-container-info.png" /&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href="https://twitter.com/TomasTomec"&gt;Tomáš Tomeček&lt;/a&gt;, a senior software engineer at &lt;a href="http://www.redhat.com/"&gt;Red Hat&lt;/a&gt; presented &amp;ldquo;sen: Easy Management of Containers in the Terminal&amp;rdquo; (&lt;a href="http://pub.tomecek.net/slides/june-2016-docker-meetup-talk/#/"&gt;slides&lt;/a&gt;). &lt;a href="http://github.com/tomastomecek/sen"&gt;sen&lt;/a&gt; is a classic open-source tool that was developed by Tomáš to &amp;ldquo;scratch his own itch.&amp;rdquo;&lt;/p&gt;

&lt;p&gt;Specifically, sen (the Czech word for dream) is the result of a dream Tomáš had about a better management interface for working with docker containers. Tomáš loves python and text user interfaces and has combined these with his love containers to build a control/dashboard for a docker daemon that provides instant access to information and commands. His top-like user interface provides easy access to the old docker-tree display for image layers, filtering and searching for images and containers, real time log access, event notifications, and more all with vim key bindings. This has replaced hacky aliases and long docker commands for his use cases.&lt;/p&gt;

&lt;p&gt;Pavel Odvody, our second lighting talk speaker and also a senior software engineer at Red Hat presented &amp;ldquo;Host Integrated Container Applications (HICA)&amp;rdquo; (&lt;a href="https://podvody.fedorapeople.org/HICA_%20Host%20Integrated%20Container%20Applications.pdf"&gt;slides&lt;/a&gt;). Developed originally as part the third Docker Global Hack Day, &lt;a href="http://github.com/shaded-enmity/docker-hica"&gt;HICA&lt;/a&gt; is designed to make it easy to run non-server containers.&lt;/p&gt;

&lt;p&gt;Pavel started his talk by asking how many people had ever tried to run a desktop application in a container. He then asked how many people had tried to run a utility, like a command line tool that processes input and returns output. These use cases while possible typically require an arcane spell book of incantations on the command line. HICA uses a secure, SELinux-compatible interface that turns labels on a docker image into a series of feature injectors to make it easy for a container to self-describe its needs. These injectors can allow a container to easily access the current working directory or the XServer on the host, or 13 other commonly needed features without requiring the user to specify them on the command line. The whole thing is wrapped in an easy-to-use CLI that has multiple levels of security and permissions and verification baked in.&lt;/p&gt;

&lt;p&gt;HICA turns this:&lt;/p&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;docker run -i -u 1000:1000 --security-opt label:disable --volume /tmp/.X11-unix:/tmp/.X11-unix -e DISPLAY=:0 --volume=/lib64/libX11.so.6:/external_libs/libX11.so.6 --volume=/lib64/libxcb-dri2.so.0:/external_libs/libxcb-dri2.so.0 --volume=/usr/lib64/dri/i965_dri.so:/external_libs/i965_dri.so --volume=/lib64/libGL.so.1:/external_libs/libGL.so.1 --volume=/lib64/libdrm_intel.so.1:/external_libs/libdrm_intel.so.1 --volume=/lib64/libxcb.so.1:/external_libs/libxcb.so.1 -e LD_LIBRARY_PATH=/external_libs -e LIBGL_DRIVERS_PATH=/external_libs --device /dev/dri/card0:/dev/dri/card0 --device /dev/dri/renderD128:/dev/dri/renderD128 --device /dev/dri/controlD64:/dev/dri/controlD64 opengl
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;into this:&lt;/p&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;hica opengl
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;After the lightning talks, we took our final break and returned to small presentation from our second sponsor, Red Hat. &lt;a href="https://twitter.com/JiriFolta"&gt;Jiří Folta&lt;/a&gt; told about Red Hat&amp;rsquo;s continuing involvement in technologies encompassing the entire stack all the way through to the hybrid public/private cloud. He also let us know that a milestone has been reach with just over 1,000 people now working for Red Hat in Brno, continuing its position as Red Hat&amp;rsquo;s largest engineering site in the world.&lt;/p&gt;

&lt;p&gt;&lt;img alt="picture of Adam Skotnický" width="800" height="533" src="/images/adam.jpg?1633620578" /&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href="https://twitter.com/ada_sko"&gt;Adam Skotnický&lt;/a&gt; and &lt;a href="https://twitter.com/MCeloud"&gt;Marek Čeloud&lt;/a&gt; from &lt;a href="http://tcpcloud.eu"&gt;tcp ◕ cloud&lt;/a&gt; presented &amp;ldquo;SmartCity IoT on Kubernetes.&amp;rdquo; Adam is the CEO and Marek is a network engineer. Their presentation brought together work they have been doing combining Kubernetes, OpenStack, and the Internet of Things to enable Smart City/Industry-4.0 infrastructures.&lt;/p&gt;

&lt;p&gt;Adam began the talk by providing an overview of a collaborative pilot smart-streetlight project being worked on in the southern Boehemian town of Písek. He then transitioned to a demo-architecture based on the same principals they have that links together carbon-dioxide sensors in a conference hall. The sensor network communicates with IQRF to a Raspberry PI running Kubernetes-managed containers. The containers utilize an OpenContrail SDN to connect back to a Kubernetes managed application that relies on virtual machines managed in OpenStack (also containerized). The SDN allows the sensor network and gateway Raspberry Pi to be relocated anywhere in the world and not need any reconfiguration.&lt;/p&gt;

&lt;p&gt;While the underlying physical unit IPs may change, the separation of networks renders this invisible to the application while simultaneously introducing security separation. Marek continued the talk with a demonstration of their internal network, the several layers of SDN in use, and how they can use a salt driven configuration to do a rolling version change of OpenStack from Kilo to Liberty. In the final conversation they talked about their need to develop their own CI/CD pipelines to build the upstream source of the fast moving Kubernetes and OpenContrail projects (amongst others). The container architecture has enabled easy distribution of the application and made it scale horizontally to the point that neither IQRF or the use of a Raspberry Pi as a gateway are limiting factors for sensor networks in urban areas.&lt;/p&gt;

&lt;p&gt;Our speakers all did an excellent job and I am thankful for all of them. I personally walked away enlightened and with new tools I want to go play with. I also walked away with a reminder of just how wicked smart my co-workers at Red Hat are and how fantastic the skill level of my community is. I need to keep bringing my A-game to my adopted city.&lt;/p&gt;

&lt;p&gt;The meetup was made possible through the generosity of our sponsors: Red Hat, who provided funding to rent the venue and Kiwi.com, who provided 128 &lt;q&gt;bits&lt;/q&gt; of refreshment to keep us engaged.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;(Photos by &lt;a href="https://photos.google.com/share/AF1QipPEXXzTVSUQpvqjCnz0Vd8Eaef26q5sayjI4-vx-ZxvLfya3I02N0Kfivy6wo5-xA?key=R0pCNVR2cWxoOFJUekFNbVoyYV83TmhPNElOc2tR"&gt;Eliska Slobodova&lt;/a&gt;.  Sen screenshot by &lt;a href="https://twitter.com/TomasTomec"&gt;Tomáš Tomeček&lt;/a&gt;.)&lt;/em&gt;&lt;/p&gt;
</content>
  </entry>
  <entry>
    <title>What Happened at the 2nd Big Docker Meetup in Brno, Czech Republic on 15 October 2015 @ 6 pm</title>
    <link rel="alternate" href="http://www.projectatomic.io/blog/2015/11/docker-brno-meetup-2/"/>
    <id>http://www.projectatomic.io/blog/2015/11/docker-brno-meetup-2/</id>
    <published>2015-11-03T21:10:20+00:00</published>
    <updated>2021-10-07T14:03:16+00:00</updated>
    <author>
      <name>Brian (bex) Exelbierd</name>
    </author>
    <content type="html">&lt;p&gt;&lt;a href="https://plus.google.com/photos/111655466984621162361/albums/6205968149218406801/6205968150060842418?pid=6205968150060842418&amp;oid=111655466984621162361"&gt;&lt;img src="https://lh6.googleusercontent.com/-M4Fe5iq6_Uc/ViAHJt_DvbI/AAAAAAAAO4A/gYCxoHSqWTA/w779-h438-no/NI2S1352.jpg" width="200" height="115"&gt;&lt;/a&gt;The &lt;a href="http://www.meetup.com/Docker-Brno/events/225508213/"&gt;Docker Brno Meetup&lt;/a&gt; group had its second big meeting on 15 October 2015 at 6 pm at the &lt;a href="http://maps.google.com/maps?f=q&amp;amp;hl=en&amp;amp;q=Cyrilsk%C3%A1+7%2C+Brno%2C+cz"&gt;Impact Hub&lt;/a&gt; in Brno, Czech Republic.  This meeting followed up a monthly set of more informal gatherings in pubs around the city and the &lt;a href="http://www.projectatomic.io/blog/2015/05/docker-meetup-brno/"&gt;first meeting on 18 May 2015&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;

&lt;p&gt;The meeting was attended by about a 100 people.  &lt;a href="https://twitter.com/JanBleha"&gt;Jan Bleha&lt;/a&gt;, the main organizer and our host for the evening surveyed the crowd with some demographic questions:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;~20 people were visiting from other cities&lt;/li&gt;
&lt;li&gt;~20 people are currently studying at University&lt;/li&gt;
&lt;li&gt;~85% of the group is actively experimenting with containers&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;a href="http://www.twitter.com/vpavlin"&gt;Václav Pavlín&lt;/a&gt; from Red Hat presented, &lt;a href="https://drive.google.com/a/redhat.com/file/d/0B5OHcgvKZLcdSGV6Q1BiOTVYUlE/view"&gt;&lt;q&gt;Nulecule: Packaging, Distributing &amp; Deploying Container Applications the Cloud Way.&lt;/q&gt;&lt;/a&gt; He notes that docker brought us container packaging and made container portability more accessible.  However, a container image is just a filesystem and some metadata about the image, but not dependencies and installation considerations.  This creates a challenge for multi-container applications as there is no built-in way to specify dependencies and other installation parameters.  We could use labels, but that could lead to a mess of labels and still no clear way to execute them or a clean way to let people know how to run or use the image.  &lt;/p&gt;

&lt;p&gt;The current UX of choice for muli-container applications is the README or the even more scary &lt;code&gt;curl http://really.not.dangerous.com/install.sh | bash&lt;/code&gt; No one likes these options as is evidenced by everyone packaging their own version of tools.  For example, there are 454 MariaDB images on DockerHub right now.&lt;/p&gt;

&lt;p&gt;The Nulecule specification provides a way to specify all of the images that are required to run an application and provides for their discovery.  It also cleanly defines how the containers interelate and what parameters, storage, etc. they require.  It also allows them to be operated on as a group and to be handed off to various orchestration providers easily, even though the orchestrators currently all have unique and mostly incompatible format for their specifications.  Atomic App is the reference implementation of the Nulecule spec, and with the &amp;rsquo;/usr/bin/atomic&amp;rsquo; helper command can reduce a multi-container application to a single line &lt;code&gt;atomic run application&lt;/code&gt; or without the helper, a single long docker command.&lt;/p&gt;

&lt;p&gt;The specification is open and not dependent on a specific container technology or orchestrator.  It allows for easy tweaking of application meta-data and parameters when moving between environments, i.e. from DEV to TEST to PRODUCTION.&lt;/p&gt;

&lt;p&gt;In a follow-up demo, Vaclav showed off the standard &lt;a href="https://github.com/projectatomic/nulecule/tree/master/examples/guestbook-go"&gt;guestbook-go example&lt;/a&gt; and a single line installation of &lt;a href="https://github.com/navidshaikh/nulecule/tree/fix-160/examples/gitlab-centos7-atomicapp"&gt;Gitlab&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;a href="https://cz.linkedin.com/in/yurytsarev"&gt;Yury Tsarev&lt;/a&gt; from GoodData presented, &lt;a href="https://drive.google.com/a/redhat.com/file/d/0B5OHcgvKZLcdcFJkbGZVQkZvTnM/view"&gt;&lt;q&gt;Test Driven Infrastrucure with Docker, Test Kitchen and Serverspec&lt;/q&gt;&lt;/a&gt;  Yury strongly believes that infrastructure code should be treated like any other code.  This means apply a test driven development model, storing it in a source control system and building a regression test suite.  He suggests doing this with &lt;a href="http://kitchen.ci"&gt;Test Kitchen&lt;/a&gt;, a pluggable and extensible test orchestrator that originated in the Chef community.  Using Test Kitchen&amp;rsquo;s &lt;a href="http://github.com/portertech/kitchen-docker"&gt;docker provider&lt;/a&gt;, a docker container can be used to simulate a machine under test.  Then &lt;a href="http://serverspec.org"&gt;Serverspec&lt;/a&gt; can verify that the configuration code, Puppet in Yury&amp;rsquo;s case, properly setup the machine.  Shell mocking is used to bypass external dependencies and docker limitations.&lt;/p&gt;

&lt;p&gt;This method creates an infrastructure change process that is: write a spec; verify it tests red; write puppet code; verify it tests green; commit via a pull request.  This leverages test-driven development and adds the benefits of scratch environment testing, testing in isolation, easy testing of permutations, resource efficiency, fast feedback and a naturally growing regression suite.&lt;/p&gt;

&lt;p&gt;At this point we took a break for some networking time, indepth Q&amp;amp;A, and some beer provided by our sponsors, &lt;a href="http://community.redhat.com"&gt;Red Hat&lt;/a&gt;, &lt;a href="http://onas.seznam.cz"&gt;Seznam.cz&lt;/a&gt; and &lt;a href="http://www.gooddata.com/"&gt;GoodData&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;a href="https://cz.linkedin.com/in/matteoferraroni"&gt;Matteo Ferraroni&lt;/a&gt; from Digital-blue presented, &lt;a href="https://drive.google.com/a/redhat.com/file/d/0B5OHcgvKZLcdaHhnR1JaX1VRNEk/view"&gt;&lt;q&gt;Ceph and Docker: How to get persistent storage on the cloud.&lt;/q&gt;&lt;/a&gt;  They have been challenged to provide persistent storage on hosts in the cloud when migrating containers from host-to-host.  While persistent storage isn&amp;rsquo;t always best practice, some applications, such as Databases, need persistent storage.  Initially they used Fleet as an orchestrator, but whenever they had a migration from host-to-host they lost their storage.  This is because most hypervisors and orchestrators provide storage as a data volume from the local host.  They have implemented a solution where they let the container mount a device exposed by the Ceph RADOS (Reliable Automatic Distributed   Ojbect Store) protocol.  The container then mounts it as a normal filesystem via fstab.  This is superior to data-only containers (&amp;ndash;volumes-from) and mapped host filesystems (-v) as you elminiate the risk of orphaned data nodes if a container gets deleted and the data isn&amp;rsquo;t cleaned up.&lt;/p&gt;

&lt;p&gt;Ceph is a unified distributed storage system designed for performance, reliability and scalability.  It works with lots of systems including most cloud providers and OpenStack.  Ceph stores client data as objects in storage pools.  Its CRUSH algorithm calculates placement for scalability, rebalacing and recovery.  There are always at least 2 copies of data at any time.  The workflow is only two steps: Ceph maps the raw storage to a device in the kernel and the device is mounted in the container (requires the &amp;ndash;cap-add=SYS_ADMIN flag).  To ensure that everything works, a systemd ExecStartPre script is executed to map the storage and retrieve the proper device name.  The device name is then passed to the container in the ExecStart.  This is done via systemd because many orchestrators (including Fleet and Mesos) cannot execute commands on the host before starting the container.  An ExecStopPost script ensures that storage is unmounted properly.&lt;/p&gt;

&lt;p&gt;Performance has been near SAN quality and is mostly affected by the networking between the Ceph infrastructure components.  This has been superior to NFS as there is no need to worry about limitations around network, fail over, etc.  Additionally, NFS doesn&amp;rsquo;t provide object storage, which is a requirement in this case.&lt;/p&gt;

&lt;p&gt;&lt;a href="https://cz.linkedin.com/in/tnozicka/en"&gt;Tomáš Nožička&lt;/a&gt; from Seznam.cz presented, &lt;a href="https://drive.google.com/a/redhat.com/file/d/0B5OHcgvKZLcdblhIOFEzTnJpRHc/view"&gt;&lt;q&gt;Using Docker for Advanced Testing: Building Packages for Multiple Distributions and Altogether.&lt;/q&gt;&lt;/a&gt;  This strategy was inspired by his team&amp;rsquo;s development an open source C++14 wrapper for libmyusqlclient.  They wanted to be able to use a dockerized mysql server in tests during the build process.  They also wanted to use docker to build for multiple distributions and to ensure a clean build environment with clean dependencies.  However, you cannot build packages which have tests that require docker using docker using today&amp;rsquo;s standard tools.&lt;/p&gt;

&lt;p&gt;Two options were considered for how to resolve this.  The first is to run docker-next-to-docker where you mount the host docker daemon&amp;rsquo;s socket into the container.  But this shares the daemon and cache across tests and may not be as clean and secure as desired.  This also requires careful work to ensure the docker client and server are in sync.  This is hard across distributions.&lt;/p&gt;

&lt;p&gt;Therefore they went with docker-in-docker using the docker:dind image from Docker Hub.  Their solution, &lt;a href="https://github.com/seznam/dbuilder"&gt;dbuilder&lt;/a&gt;, leverages this to provide a separate docker daemon and cache to each build/test container.  This open-source framework also provides a yaml configruation file mechanism for Dockerfiles so that you do not have to manage all of the permutations required for different environments and distributions.&lt;/p&gt;

&lt;p&gt;Tomáš also provided some general comments on what they are seeing with docker in production.  They have some challenges related to logging as logstash was running too slowly in their production environment.  Right now they are bind mounting out the logs and collecting them, but are looking at other options.  They continue to find service discovery and orchestration to be thorny problems are are still exploring the plethora of options available.&lt;/p&gt;

&lt;p&gt;In closing, Jan, asked our audience some more questions and we learned that:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;~50% of our group runs containers somewhere in production&lt;/li&gt;
&lt;li&gt;~60% of our group uses docker in production&lt;/li&gt;
&lt;li&gt;Only about 10 people have jobs that are defined to include docker&lt;/li&gt;
&lt;li&gt;Only about 12 people are running applications that use 3 or more images&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Before the meeting, a small group of system administrators, programmers and enthusiasts, who had never used Docker before, got together for a Docker 101 workshop (&lt;a href="http://redhat.slides.com/jkarasek/docker101#/"&gt;slides&lt;/a&gt;). This workshop, lead by two Red Hat engineers, Peter Schiffer and &lt;a href="http://redhat.slides.com/jkarasek"&gt;Josef Karasek&lt;/a&gt;, was intended to ease the first steps with Docker for the participants. After a brief talk on the the theory behind containers the particpants (who all showed up with docker preinstalled) practiced pulling docker images from Docker hub, creating new images, and running containers. Additional topics covered during the workshop were container networking, volumes and linking of multiple containers.&lt;/p&gt;

&lt;p&gt;I want to thank Jan Bleha for organizing the event, &lt;a href="https://photos.google.com/share/AF1QipPQlkx06KQ4sOwEB6PH3GczQxJwI_tNMNbwPPvzFl2XDQ3oWUrdx7A0Ml-GcVMjew?key=blNtZ1o3VmVuaGYwS2N5Um90NkY4cFI5Sk5WMGNn"&gt;Jiri Folta&lt;/a&gt; for the great photos and Red Hat, seznam.cz and GoodData for sponsoring the venue and refreshments.&lt;/p&gt;
</content>
  </entry>
  <entry>
    <title>Report on the Container Keynote Panel from LinuxCon EU 2015</title>
    <link rel="alternate" href="http://www.projectatomic.io/blog/2015/10/container-roundtable-linuxcon-eu/"/>
    <id>http://www.projectatomic.io/blog/2015/10/container-roundtable-linuxcon-eu/</id>
    <published>2015-10-14T13:46:51+00:00</published>
    <updated>2021-10-07T14:03:16+00:00</updated>
    <author>
      <name>Brian (bex) Exelbierd</name>
    </author>
    <content type="html">&lt;p&gt;At &lt;a href="http://events.linuxfoundation.org/events/linuxcon-europe"&gt;LinuxCon Europe 2015&lt;/a&gt; from 5-7 October, 2015 in Dublin, Ireland. Project Atomic&amp;rsquo;s Joe Brockmeier &lt;a href="http://sched.co/3xqB"&gt;moderated a panel discussion&lt;/a&gt; between Tom Barlow from Docker, Sebastien Goasguen of Citrix, and Brandon Philips from CoreOS about containers.  &lt;/p&gt;

&lt;p&gt;As you may know, the technology underlying containers is not new and that a big part of the innovation provided by Docker and others is essentially an easier way to package and access this technology. However, there are key questions ahead as the technology continues to mature and transcend the &lt;q&gt;it&amp;rsquo;s just packaging&lt;/q&gt; idea.  I didn&amp;rsquo;t transcribe the entire session, but I wanted to call out a few of the exchanges and how they affect various roles.&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;

&lt;p&gt;First the difference between application containers and system containers was stressed by Brandon from CoreOS and agreed with by the panel.  System containers are characterized by the use of an init system and typically contain multiple pieces of an application and supporting services like ssh.  This is treating containers as lightweight virtual machines.  This was the original pattern that many users adopted, but it is now seen as sub-optimal.  &lt;/p&gt;

&lt;p&gt;Application containers, on the other hand, are based on the idea of one microservice (or service or application component) per container. This model allows for more library independence, easier scaling and development.&lt;/p&gt;

&lt;p&gt;Wearing my operations hat, I particularly liked an exchange that started with a question from Joe about whether we are actually moving backwards from packaging and forgetting the 20 years of lessons we have learned with technology like RPM and apt.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Brandon responded by saying that in his opinion RPM and apt failed because they are great for distributions, but not for custom apps.  Building software is complex and people resort to wget/rsync/git checkout instead of trying to package their applications.  Containers recognize this, although, as he acknowledged, you are giving up updates and auditability today.&lt;/li&gt;
&lt;li&gt;Sebastien noted that there is a big trust issue that needs to be talked about.  DockerHub is an amazing resource and deploying apps has never been this easy, but we need to go further and ensure we have trust, signatures and upgradability.  He also acknowledged that the goal of trust is not necessarily fully realized today.  Every time we install a JavaScript library, for example, with NPM, we are probably not really doing our full due diligence in verifying the package.  So we need to get the container model quickly to one where trusted images are running in production.&lt;/li&gt;
&lt;li&gt;Tom extended these thoughts by saying that we need to develop and apply a &lt;q&gt;ton&lt;/q&gt; of best practices.  We are still seeing multi-gig images that haven&amp;rsquo;t been stripped of dev/test dependencies.  Signed images and trust from a vendor are required and need to be gotten.  Notary is a good idea, but we need to go beyond GPG signing because of the risk of key compromise.  Today, Notary is not going to introspection and will still rely on external tools.  This is on the roadmap and is important.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;As a developer, the discussion about service discovery was very interesting to me.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Brandon noted that time has been spent on high-availability and fail-over and that they work fine on a small scale.  However, containers really should be using service discovery because we can do heterogeneous service composition (i.e. 80% stable build, 10% beta build, 10% experimental) in the same application.  This is a new enablement opportunity.&lt;/li&gt;
&lt;li&gt;Tom offered that service discovery is more of a spectrum.  Some applications will use traditional methods, like DNS, and will be unaware they are in a container, others will use a platform or orchestration provided service discovery mechanisms, like SkyDNS, and be more &lt;q&gt;container native.&lt;/q&gt;  We need more documentation on this and we need to &lt;a href="http://www.projectatomic.io/blog/2015/10/setting-up-skydns/"&gt;make things like SkyDNS easier to use&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Sebastien added that IBM had an Autonomic Computing Initiative that provided self-discovery, healing, etc.  Containers are getting there.  Today you can you use something like Registrator to rewrite an HAProxy/Nginx configuration and you are on your way.  This needs scale, but it works.  Before containers all of this was much harder.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;A common question in my mind, and put to the panel, is &lt;q&gt;What do existing deployments look like?&lt;/q&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Brandon has found that most folks originally think application containers are cool.  Then when you add distributed systems, people are want Google-like infrastructure.  Orchestrators like swarm and Kubernetes are pumping people up and getting them excited about the future.  However, today, CoreOS is mostly seeing people containerizing a small part of their application and experimenting with the build system before taking too big of a step forward.  While this will be slow, the benefit we get with containers is that because the technology decomposes nicely.  Therefore, it is easy to use this kind of a &lt;q&gt;small-test and see&lt;/q&gt; strategy.&lt;/li&gt;
&lt;li&gt;Tom is seeing similar use cases at the start.  Typically they are seeing people containerize their Jenkins and then their Jenkins agents.  There is still a bit of fear and this seems like the least risky way to approach the technology.  Companies that can easily get to or already have microservices are currently the best use cases.&lt;/li&gt;
&lt;li&gt;Sebastien opined that building an image from a Dockerfile and pushing it is very fast.  He is also seeing people update the small bits in the tests they are running.  For example, instead of migrating more of their application to containers, they will update from log paths to log drivers in the tiny part they have already moved and see how it goes.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Naturally, you have to ask technologists what they think is coming next, and give the audience a view into their crystal balls. &lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Brandon says we need to develop clear paths from RPM/apt content to containers that allow continuous integration systems (Jenkins, etc.) to build them.  This is what the &lt;a href="https://www.opencontainers.org/"&gt;Open Container Initiative&lt;/a&gt; is doing by addressing build, ship and sign.  We also need to evolve how containers get into production.  There are lots of &lt;q&gt;tricky&lt;/q&gt; bits that need to get sorted out and the road will be bumpy for a few years.&lt;/li&gt;
&lt;li&gt;Tom says that there is now an interesting contract between an application and the infrastructure.  Projects like Prometheus make it easier to monitor containers because of this contract.  This can be leveraged by other tools.  We also need to see how things like logging can be made easier and abstracted out for developers as part of this contract.  Additional storage solutions should come online and the challenges around service discovery, networking, signing and security should start to resolve.  Docker expects to see content trust and other innovations supplement package management and signing.&lt;/li&gt;
&lt;li&gt;Sebastien has seen thinking there is an ongoing shift from a machine management orientation to an application management orientation.  We are going to see much better monitoring and management systems which will move operations up the stack to really managing and operating applications.  Multi-container applications are going to be complex and specifications like Nulecule will help resolve this.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;I am very grateful to the panelists for this thoughtful and informed conversation.  The panel did a great job sticking to the technology and not the companies, and a great job of answering in ways that can guide us as users, whether we are customers or not. I also want to thank the organizers for making this a keynote session so I didn&amp;rsquo;t have to choose between other sessions at the conference and this one.&lt;/p&gt;
</content>
  </entry>
  <entry>
    <title>Upcoming Docker Meetup in Brno, Czech Republic - 15 October 2015 @ 6 pm</title>
    <link rel="alternate" href="http://www.projectatomic.io/blog/2015/10/docker-brno-meetup/"/>
    <id>http://www.projectatomic.io/blog/2015/10/docker-brno-meetup/</id>
    <published>2015-10-09T00:52:32+00:00</published>
    <updated>2021-10-07T14:03:16+00:00</updated>
    <author>
      <name>Brian (bex) Exelbierd</name>
    </author>
    <content type="html">&lt;p&gt;The &lt;a href="http://www.meetup.com/Docker-Brno/events/225508213/"&gt;Docker Brno Meetup&lt;/a&gt; group will have its next meeting on 15 October 2015 at 6 pm at the &lt;a href="http://maps.google.com/maps?f=q&amp;amp;hl=en&amp;amp;q=Cyrilsk%C3%A1+7%2C+Brno%2C+cz"&gt;Impact Hub&lt;/a&gt; in Brno, Czech Republic.  Four talks are planned for the meeting to address a wide range of docker users and people interested in learning more.  The community element will be enhanced by visitors from the  Docker Bratislava, Docker Prague and Docker Krakow Meetup groups.&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;a href="http://www.twitter.com/vpavlin"&gt;Václav Pavlín&lt;/a&gt; from Red Hat will present, &lt;q&gt;Nulecule - how to define, distribute and deploy multi-container applications.&lt;/q&gt;  There is no standard mechanism for creating, distributing and deploying multi-container applications.  The Nulecule specification solves this problem by allowing the definition, metadata, dependencies and orchestration provider configurations to be packaged up into a single usable unit.  This talk will also cover Atomic App, the reference implementation of Nulecule.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href="https://cz.linkedin.com/in/matteoferraroni"&gt;Matteo Ferraroni&lt;/a&gt; from Digital-blue will present, &lt;q&gt;Ceph and Docker: How to get persistent storage on the cloud.&lt;/q&gt;  Docker promises that you can &lt;q&gt;Build, Ship, and Run Any App, Anywhere,&lt;/q&gt; but what happens when you need an enterprise-grade multiple host environment to run your production applications?  Digital-blue discovered that the storage solutions provided out-of-the-box by Docker has some gaps. This led to them seeking a way to provide reliable persistent storage to their containers running in a multi-host environment.  Ultimately the solution was found with CEPH.  This talk will explain the gaps in the Docker storage subsystem and how CEPH can be used to provide persistent storage.  There will also be a hands-on lab where the audience can try out the solution.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href="https://cz.linkedin.com/in/yurytsarev"&gt;Yury Tsarev&lt;/a&gt; from GoodData will present, &lt;q&gt;Using docker together with test kitchen and serverspec for puppet test automation.&lt;/q&gt;  Learn how to win at &lt;q&gt;buzzword bingo&lt;/q&gt; by combining two popular testing tools with docker to create a &lt;q&gt;test-driven infrastructure.&lt;/q&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href="https://cz.linkedin.com/in/tnozicka/en"&gt;Tomáš Nožička&lt;/a&gt; from Seznam.cz will present, &lt;q&gt;Using docker for advanced testing, building packages for multiple distributions and altogether.&lt;/q&gt; This two-part presentation will start with a demonstration of using docker for unit testing when a database, such as MySQL, is required.  In the second part code will be tested and built in a clean environment for multiple distributions using docker.  In this second part we will explore using &lt;q&gt;docker in docker&lt;/q&gt; and &lt;q&gt;docker next to docker&lt;/q&gt; as part of the solution.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;I look forward to seeing you there and to interacting with you and other community members.  Show up with questions and excitement.&lt;/p&gt;
</content>
  </entry>
</feed>

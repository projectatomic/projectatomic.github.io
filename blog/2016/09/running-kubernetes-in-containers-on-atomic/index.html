<!DOCTYPE html>
<!--[if lt IE 7]> <html class="no-js lt-ie10 lt-ie9 lt-ie8 lt-ie7" lang="en-us"> <![endif]-->
<!--[if IE 7]> <html class="no-js lt-ie10 lt-ie9 lt-ie8" lang="en-us"> <![endif]-->
<!--[if IE 8]> <html class="no-js lt-ie10 lt-ie9" lang="en-us"> <![endif]-->
<!--[if IE 9]> <html class="no-js lt-ie10 lt-ie9" lang="en-us"> <![endif]-->
<!--[if lt IE 10]> <html class="no-js lt-ie10" lang="en-us"> <![endif]-->
<!--[if !IE]> > <![endif]-->
<html class='no-js' lang='en'>
<!-- <![endif] -->
<head>
<title>
Running Kubernetes and Friends in Containers on CentOS Atomic Host &mdash;
Project Atomic
</title>
<meta charset='utf-8'>
<meta content='' name='description'>
<meta content='Jason Brooks' name='author'>
<meta content='initial-scale=1.0,user-scalable=no,maximum-scale=1,width=device-width' name='viewport'>
<link href='/blog/feed.xml' rel='alternate' title='Atom feed' type='application/atom+xml'>
<!-- Open Graph (FB / G+) -->
<meta content='article' property='og:type'>
<meta content='Running Kubernetes and Friends in Containers on CentOS Atomic Host' property='og:title'>
<meta content='The atomic hosts from CentOS and Fedora earn their atomic namesake by providing for atomic, image-based system updates via rpm-ostree, and atomic, image-based application updates via docker containers.&#x000A;&#x000A;This system vs application division isn’t set in stone, however. There’s room for system components to move across from the somewhat rigid world of ostree commits to the freer-flowing container side.&#x000A;&#x000A;In particular, the key atomic host components involved in orchestrating containers across multiple hosts, such as flannel, etcd and kubernetes, could run instead in containers, making life simpler for those looking to test out newer or different versions of these components, or to swap them out for alternatives.&#x000A;&#x000A;The devel tree of CentOS Atomic Host, which features a trimmed-down system image that leaves out kubernetes and related system components, is a great place to experiment with alternative methods of running these components, and swapping between them.' property='og:description'>
<meta content='https://www.projectatomic.io/blog/2016/09/running-kubernetes-in-containers-on-atomic/' property='og:url'>
<meta content='2016-09-15T12:00:00Z' property='article:published_time'>
<meta content='jbrooks' property='article:author:username'>
<meta content='atomic' property='article:tag'>
<link href='/blog/tag/atomic.xml' rel='alternate' title='Atom feed' type='application/atom+xml'>
<meta content='centos' property='article:tag'>
<link href='/blog/tag/centos.xml' rel='alternate' title='Atom feed' type='application/atom+xml'>
<meta content='docker' property='article:tag'>
<link href='/blog/tag/docker.xml' rel='alternate' title='Atom feed' type='application/atom+xml'>
<meta content='kubernetes' property='article:tag'>
<link href='/blog/tag/kubernetes.xml' rel='alternate' title='Atom feed' type='application/atom+xml'>
<meta content='system containers' property='article:tag'>
<link href='/blog/tag/system containers.xml' rel='alternate' title='Atom feed' type='application/atom+xml'>
<!-- Twitter card -->
<meta content='summary' name='twitter:card'>
<meta content='Running Kubernetes and Friends in Containers on CentOS Atomic Host' name='twitter:title'>
<meta content='The atomic hosts from CentOS and Fedora earn their atomic namesake by providing for atomic, image-based system updates via rpm-ostree, and atomic, image-based application updates via docker containers.&#x000A;&#x000A;This system vs application division isn’t set in stone, however. There’s room for system components to move across from the somewhat rigid world of ostree commits to the freer-flowing container side.&#x000A;&#x000A;In particular, the key atomic host components involved in orchestrating containers across multiple hosts, such as flannel, etcd and kubernetes, could run instead in containers, making life simpler for those looking to test out newer or different versions of these components, or to swap them out for alternatives.&#x000A;&#x000A;The devel tree of CentOS Atomic Host, which features a trimmed-down system image that leaves out kubernetes and related system components, is a great place to experiment with alternative methods of running these components, and swapping between them.' name='twitter:description'>

<link href='/images/favicon.ico' rel='shortcut icon'>
<link href='/images/apple-touch-icon-precomposed.png' rel='apple-touch-icon-precomposed'>
<link href='/images/apple-touch-icon-57x57-precomposed.png' rel='apple-touch-icon-precomposed' sizes='57x57'>
<link href='/images/apple-touch-icon-72x72-precomposed.png' rel='apple-touch-icon-precomposed' sizes='72x72'>
<link href='/images/apple-touch-icon-114x114-precomposed.png' rel='apple-touch-icon-precomposed' sizes='114x114'>
<link href='/blog/feed.xml' rel='alternate' title='Project Atomic' type='application/atom+xml'>
<link href="/stylesheets/application.css?1633620577" rel="stylesheet" type="text/css" />
<link href="/stylesheets/print.css?1633620578" rel="stylesheet" type="text/css" media="print" />
<div class="alert alert-danger text-center">
<h2> Project Atomic is now sunset</h2>
<p>
The Atomic Host platform is now replaced by <a href="https://coreos.fedoraproject.org">CoreOS</a>.
Users of Atomic Host are encouraged to join the CoreOS community on the <a href="https://github.com/coreos/fedora-coreos-tracker#communication-channels-for-fedora-coreos">Fedora CoreOS communication channels</a>.
</p>
<p>
The documentation contained below and throughout this site has been retained for historical purposes, but can no longer be guaranteed to be accurate.
</p>
</div>

</head>
<body class=' blog blog_2016 blog_2016_09 blog_2016_09_running-kubernetes-in-containers-on-atomic blog_2016_09_running-kubernetes-in-containers-on-atomic_index source-md'>
<section class='container' id='page-wrap'>
<div class='row'>
<div class='col-md-3 col-lg-2' id='sidebar'>
<div id='nav-primary'>
<nav class='navbar navbar-default' role='navigation'>
<div class='navbar-header'>
<button class='navbar-toggle' data-target='.navbar-ex1-collapse' data-toggle='collapse'>
<span class='sr-only'>
Toggle navigation
</span>
<span class='icon-bar'></span>
<span class='icon-bar'></span>
<span class='icon-bar'></span>
</button>
<a class='navbar-brand' href='/'>
Project Atomic
</a>
</div>
<div class='collapse navbar-collapse navbar-ex1-collapse'>
<ul class='nav navbar-nav'>
<li><a class="get-started" href="/download">Get Started</a></li>
<li><a class="documentation" href="/docs">Documentation</a></li>
<li><a class="developer-community" href="/community">Developer Community</a></li>
<li><a class="talks" href="/community/talks">Talks</a></li>
<li><a class="on-github" href="https://github.com/projectatomic/">On GitHub</a></li>
<li><a class="blog" href="/blog">Blog</a></li>
<li><a class="twitter" href="http://www.twitter.com/projectatomic">Twitter</a></li>
<li><a class="rss" href="../../../feed.xml">RSS</a></li>
</ul>
</div>
</nav>

</div>

</div>
<section class='col-lg-10 col-md-9 container' id='content'>
<!--[if lt IE 7]>
<p class="chromeframe">You are using an outdated browser.
<a href="http://browsehappy.com/">Upgrade your browser today</a> or
<a href="http://www.google.com/chromeframe/?redirect=true">install Google Chrome Frame</a> to better experience this site.</p>
<![endif]-->
<section class='blog-post-page row'>
<div class='col-md-12'>
<article class='post hentry'>
<header class='post-header'>
<h2 class='post-title entry-title'>
Running Kubernetes and Friends in Containers on CentOS Atomic Host
</h2>
<p class='post-meta'>
<span class='byline'>
by
</span>
<span class='author vcard'>
<a href="/blog/author/jbrooks/">Jason Brooks</a>
</span>
&ndash;
<time class='published' datetime='2016-09-15T12:00:00Z'>
Thursday 15 September 2016
</time>
</p>
</header>
<section class='post-content entry-content'>
<p>The <a href="http://www.projectatomic.io/docs/introduction/">atomic hosts</a> from CentOS and Fedora earn their <q>atomic</q> namesake by providing for atomic, image-based system updates via rpm-ostree, and atomic, image-based application updates via docker containers.</p>

<p>This <q>system</q> vs <q>application</q> division isn&rsquo;t set in stone, however. There&rsquo;s room for system components to move across from the <a href="http://www.projectatomic.io/blog/2016/07/hacking-and-extending-atomic-host/">somewhat</a> rigid world of ostree commits to the freer-flowing container side.</p>

<p>In particular, the key atomic host components involved in orchestrating containers across multiple hosts, such as flannel, etcd and kubernetes, could run instead in containers, making life simpler for those looking to test out newer or different versions of these components, or to swap them out for alternatives.</p>

<p>The <a href="https://wiki.centos.org/SpecialInterestGroup/Atomic/Devel">devel tree</a> of CentOS Atomic Host, which features a trimmed-down system image that leaves out kubernetes and related system components, is a great place to experiment with alternative methods of running these components, and swapping between them.</p>

<p></p>

<h3>System Containers</h3>

<p>Running system components in docker containers can be tricky, because these containers aren&rsquo;t automatically integrated with systemd, like other system services, and because some components, such as flannel, need to modify docker configs, resulting in a bit of a chicken-and-egg situation.</p>

<p>One solution is <a href="http://www.projectatomic.io/blog/2016/09/intro-to-system-containers/">system containers for atomic</a>, which can be run independently from the docker daemon. <a href="https://twitter.com/gscrivano">Giuseppe Scrivano</a> has built example containers <a href="https://hub.docker.com/r/gscrivano/flannel/">for flannel</a> and <a href="https://hub.docker.com/r/gscrivano/etcd/">for etcd</a>, and in this post, I&rsquo;ll be using system containers to run flannel and etcd on my atomic hosts.</p>

<p>You need a very recent version of the <code>atomic</code> command. I used a pair of CentOS Atomic Hosts running the <a href="https://wiki.centos.org/SpecialInterestGroup/Atomic/Devel"><q>continuous</q></a> stream.</p>

<p>The master host needs etcd and flannel:</p>
<pre class="highlight plaintext"><code># atomic install --system gscrivano/etcd&#x000A;&#x000A;# systemctl start etcd&#x000A;</code></pre>

<p>With etcd running, we can use it to configure flannel:</p>
<pre class="highlight plaintext"><code># runc exec etcd etcdctl set /atomic.io/network/config '{"Network":"172.17.0.0/16"}'&#x000A;&#x000A;# atomic install --system gscrivano/flannel&#x000A;&#x000A;# systemctl start flannel&#x000A;</code></pre>

<p>The worker node needs flannel as well:</p>
<pre class="highlight plaintext"><code># export MASTER_IP=YOUR-MASTER-IP&#x000A;&#x000A;# atomic install --system --set FLANNELD_ETCD_ENDPOINTS=http://$MASTER_IP:2379 gscrivano/flannel&#x000A;&#x000A;# systemctl start flannel&#x000A;</code></pre>

<p>On both the master and the worker, we need to make docker use flannel:</p>
<pre class="highlight plaintext"><code># echo "/usr/libexec/flannel/mk-docker-opts.sh -k DOCKER_NETWORK_OPTIONS -d /run/flannel/docker" | runc exec flannel bash&#x000A;</code></pre>

<p>Also on both hosts, we need this docker tweak (<a href="https://github.com/kubernetes/kubernetes/issues/4869">because of this</a>):</p>
<pre class="highlight plaintext"><code># cp /usr/lib/systemd/system/docker.service /etc/systemd/system/&#x000A;&#x000A;# sed -i s/MountFlags=slave/MountFlags=/g /etc/systemd/system/docker.service&#x000A;&#x000A;# systemctl daemon-reload&#x000A;&#x000A;# systemctl restart docker&#x000A;</code></pre>

<p>On both hosts, some context tweaks to make SELinux happy:</p>
<pre class="highlight plaintext"><code># mkdir -p /var/lib/kubelet/&#x000A;&#x000A;# chcon -R -t svirt_sandbox_file_t /var/lib/kubelet/&#x000A;&#x000A;# chcon -R -t svirt_sandbox_file_t /var/lib/docker/&#x000A;</code></pre>

<h3>Kube in Containers</h3>

<p>With etcd and flannel in place, we can proceed with running kubernetes. We can run each of the kubernetes master and worker components in containers, using the rpms available in the CentOS repositories. Here I&rsquo;m using containers built from <a href="https://github.com/jasonbrooks/CentOS-Dockerfiles/tree/pr-kubernetes/kubernetes">these dockerfiles</a>.</p>

<h4>On the master</h4>
<pre class="highlight plaintext"><code># export MASTER_IP=YOUR-MASTER-IP&#x000A;&#x000A;# docker run -d --net=host jasonbrooks/kubernetes-apiserver:centos --admission-control=NamespaceLifecycle,NamespaceExists,LimitRanger,SecurityContextDeny,ResourceQuota --address=0.0.0.0 --insecure-bind-address=0.0.0.0&#x000A;&#x000A;# docker run -d --net=host --privileged jasonbrooks/kubernetes-controller-manager:centos&#x000A;&#x000A;# docker run -d --net=host jasonbrooks/kubernetes-scheduler:centos&#x000A;</code></pre>

<h4>On the worker</h4>
<pre class="highlight plaintext"><code># export WORKER_IP=YOUR-WORKER-IP&#x000A;&#x000A;# atomic run --opt3="--master=http://$MASTER_IP:8080" jasonbrooks/kubernetes-proxy:centos&#x000A;&#x000A;# atomic run --opt1="-v /etc/kubernetes/manifests:/etc/kubernetes/manifests:ro" --opt3="--address=$WORKER_IP --config=/etc/kubernetes/manifests --hostname_override=$WORKER_IP --api_servers=http://$MASTER_IP:8080 --cluster-dns=10.254.0.10 --cluster-domain=cluster.local" jasonbrooks/kubernetes-kubelet:centos&#x000A;</code></pre>

<h4>Get matching kubectl</h4>

<p>I like to test things out from my master node. We can grab the version of the kubernetes command line client, kubectl, that matches our rpms by extracting it from the CentOS rpm.</p>
<pre class="highlight plaintext"><code># rpm2cpio http://mirror.centos.org/centos/7/extras/x86_64/Packages/kubernetes-client-1.2.0-0.13.gitec7364b.el7.x86_64.rpm | cpio -iv --to-stdout "./usr/bin/kubectl" &gt; /usr/local/bin/kubectl &amp;&amp; chmod +x /usr/local/bin/kubectl&#x000A;</code></pre>

<p>We can then use kubectl to check on the status of our node(s):</p>
<pre class="highlight plaintext"><code># kubectl get nodes&#x000A;&#x000A;NAME            STATUS    AGE&#x000A;10.10.171.216   Ready     3h&#x000A;</code></pre>

<h4>DNS Addon</h4>

<p>The guestbookgo sample app that I like to use for testing requires the dns addon, so I always ensure that it&rsquo;s installed. Here I&rsquo;m following the directions from the docker-multinode page in the kube-deploy repository:</p>
<pre class="highlight plaintext"><code># curl -O https://raw.githubusercontent.com/kubernetes/kube-deploy/master/docker-multinode/skydns.yaml&#x000A;</code></pre>

<p>I skipped over setting up certificates for this cluster, so in order for the dns addon to work, the kube2sky container in the dns pod needs the argument <code>--kube-master-url=http://$MASTER_IP:8080</code>. Also, I&rsquo;m changing the <code>clusterIP</code> to <code>10.254.0.10</code> to match the default from the rpms.</p>
<pre class="highlight plaintext"><code># vi skydns.yaml&#x000A;&#x000A;...&#x000A;&#x000A;- name: kube2sky&#x000A;        image: gcr.io/google_containers/kube2sky-ARCH:1.15&#x000A;        resources:&#x000A;          limits:&#x000A;            cpu: 100m&#x000A;            memory: 50Mi&#x000A;        args:&#x000A;        # command = "/kube2sky"&#x000A;        - --domain=cluster.local&#x000A;        - --kube-master-url=http://$MASTER_IP:8080&#x000A;...&#x000A;&#x000A;spec:&#x000A;  selector:&#x000A;    k8s-app: kube-dns&#x000A;  clusterIP: 10.254.0.10&#x000A;&#x000A;</code></pre>

<p>Now to start up the dns addon:</p>
<pre class="highlight plaintext"><code># kubectl create namespace kube-system&#x000A;&#x000A;# export ARCH=amd64&#x000A;&#x000A;# sed -e "s/ARCH/${ARCH}/g;" skydns.yaml | kubectl create -f -&#x000A;</code></pre>

<h3>Test it</h3>

<p>It takes a few minutes for all the containers to get up and running. Once they are, you can start running kubernetes apps. I typically test with the <a href="https://github.com/projectatomic/nulecule-library/tree/master/guestbookgo-atomicapp">guestbookgo atomicapp</a>:</p>
<pre class="highlight plaintext"><code># atomic run projectatomic/guestbookgo-atomicapp&#x000A;</code></pre>

<p>Wait a few minutes, until <code>kubectl get pods</code> tells you that your guestbook and redis pods are running, and then:</p>
<pre class="highlight plaintext"><code># kubectl describe service guestbook | grep NodePort&#x000A;</code></pre>

<p>Visiting the <code>NodePort</code> returned above at either my master or worker IP (these kube scripts configure both to serve as workers) gives me this:</p>

<p><img src="/images/guestbook-ftw.png" /></p>

<h3>A Newer Kube</h3>

<p>The kubernetes rpms in the CentOS repositories are currently at version 1.2. To try out the current, 1.3 version of kubernetes, you can swap in some newer rpms, running in Fedora or Rawhide-based containers, or you can use the latest kubernetes containers provided by the upstream project.</p>

<h4>Cleaning up</h4>

<p>If you&rsquo;ve already configured kubernetes using the above instructions, and want to start over with a different kubernetes version, you can blow your existing cluster away (while leaving the flannel and etcd pieces in place).</p>

<p>First, remove all the docker containers running on your master and node(s). On each machine, run:</p>
<pre class="highlight plaintext"><code># docker rm -f $(docker ps -a -q)&#x000A;</code></pre>

<p>Run <code>docker ps</code> to see if any containers are left over, if there are, run the command above again until they&rsquo;re all gone. Since we&rsquo;re running flannel and etcd using runc, killing all our docker containers won&rsquo;t affect our system containers.</p>

<p>Next, you can clear out the etcd keys associated with the cluster by running this on your master:</p>
<pre class="highlight plaintext"><code># runc exec -t etcd etcdctl rm --recursive /registry&#x000A;</code></pre>

<p>Then, on your worker node, clean up the <code>/var/lib/kubelet</code> directory:</p>
<pre class="highlight plaintext"><code># rm -rf /var/lib/kubelet/*&#x000A;</code></pre>

<h3>Containers from Rawhide</h3>

<p>I mentioned that the CentOS repositories contain a v1.2 kubernetes. However, Fedora&rsquo;s <a href="https://fedoraproject.org/wiki/Releases/Rawhide">Rawhide</a> includes v1.3-based kubernetes packages. howI wanted to try out the most recent rpm-packaged kubernetes, so I rebuilt the containers I used above swapping in <code>fedora:rawhide</code> for <code>centos:centos7</code> in the <code>FROM:</code> lines of the dockerfiles.</p>

<p>You can run the same series of commands listed above, with the container tag changed from <code>:centos</code> to <code>:rawhide</code>.</p>

<p>For instance:</p>
<pre class="highlight plaintext"><code># docker run -d --net=host jasonbrooks/kubernetes-scheduler:centos --master=http://$MASTER_IP:8080&#x000A;</code></pre>

<p>becomes:</p>
<pre class="highlight plaintext"><code># docker run -d --net=host jasonbrooks/kubernetes-scheduler:rawhide --master=http://$MASTER_IP:8080&#x000A;</code></pre>

<h3>Containers from Upstream</h3>

<p>With flannel and etcd running in system containers, and with docker configured properly, we can start up kubernetes using <a href="https://github.com/kubernetes/kubernetes/tree/master/cluster/images/hyperkube">the containers</a> built by the upstream kubernetes project. I&rsquo;ve pulled the following docker run commands from the <a href="https://github.com/kubernetes/kube-deploy/tree/master/docker-multinode">docker-multinode</a> scripts in the kubernetes project&rsquo;s kube-deploy repository.</p>

<p>On the master:</p>
<pre class="highlight plaintext"><code># docker run -d \&#x000A;    --net=host \&#x000A;    --pid=host \&#x000A;    --privileged \&#x000A;    --restart="unless-stopped" \&#x000A;    --name kube_kubelet_$(date | md5sum | cut -c-5) \&#x000A;    -v /sys:/sys:rw \&#x000A;    -v /var/run:/var/run:rw \&#x000A;    -v /run:/run:rw \&#x000A;    -v /var/lib/docker:/var/lib/docker:rw \&#x000A;    -v /var/lib/kubelet:/var/lib/kubelet:shared \&#x000A;    -v /var/log/containers:/var/log/containers:rw \&#x000A;    gcr.io/google_containers/hyperkube-amd64:$(curl -sSL "https://storage.googleapis.com/kubernetes-release/release/stable.txt") \&#x000A;    /hyperkube kubelet \&#x000A;      --allow-privileged \&#x000A;      --api-servers=http://localhost:8080 \&#x000A;      --config=/etc/kubernetes/manifests-multi \&#x000A;      --cluster-dns=10.0.0.10 \&#x000A;      --cluster-domain=cluster.local \&#x000A;      --hostname-override=${MASTER_IP} \&#x000A;      --v=2&#x000A;</code></pre>

<p>On the worker:</p>
<pre class="highlight plaintext"><code># export WORKER_IP=YOUR-WORKER-IP&#x000A;&#x000A;# docker run -d \&#x000A;    --net=host \&#x000A;    --pid=host \&#x000A;    --privileged \&#x000A;    --restart="unless-stopped" \&#x000A;    --name kube_kubelet_$(date | md5sum | cut -c-5) \&#x000A;    -v /sys:/sys:rw \&#x000A;    -v /var/run:/var/run:rw \&#x000A;    -v /run:/run:rw \&#x000A;    -v /var/lib/docker:/var/lib/docker:rw \&#x000A;    -v /var/lib/kubelet:/var/lib/kubelet:shared \&#x000A;    -v /var/log/containers:/var/log/containers:rw \&#x000A;    gcr.io/google_containers/hyperkube-amd64:$(curl -sSL "https://storage.googleapis.com/kubernetes-release/release/stable.txt") \&#x000A;    /hyperkube kubelet \&#x000A;      --allow-privileged \&#x000A;      --api-servers=http://${MASTER_IP}:8080 \&#x000A;      --cluster-dns=10.0.0.10 \&#x000A;      --cluster-domain=cluster.local \&#x000A;      --hostname-override=${WORKER_IP} \&#x000A;      --v=2&#x000A;&#x000A;# docker run -d \&#x000A;    --net=host \&#x000A;    --privileged \&#x000A;    --name kube_proxy_$(date | md5sum | cut -c-5) \&#x000A;    --restart="unless-stopped" \&#x000A;    gcr.io/google_containers/hyperkube-amd64:$(curl -sSL "https://storage.googleapis.com/kubernetes-release/release/stable.txt") \&#x000A;    /hyperkube proxy \&#x000A;        --master=http://${MASTER_IP}:8080 \&#x000A;        --v=2&#x000A;</code></pre>

<h4>Get current kubectl</h4>

<p>I usually test things out from the master node, so I&rsquo;ll download the newest stable kubectl binary to there:</p>
<pre class="highlight plaintext"><code># curl -sSL https://storage.googleapis.com/kubernetes-release/release/$(curl -sSL "https://storage.googleapis.com/kubernetes-release/release/stable.txt")/bin/linux/amd64/kubectl &gt; /usr/local/bin/kubectl&#x000A;&#x000A;# chmod +x /usr/local/bin/kubectl&#x000A;&#x000A;# kubectl get nodes&#x000A;</code></pre>

<p>From here, you an scroll up to the subhead <q>Test it</q> to run the guestbookgo  app. It&rsquo;s not necessary to start up the dns addon manually with these upstream containers, because this configuration starts that addon automatically.</p>

</section>
<footer class='post-meta'>
<div class='tags'>
Tags:
<ul class='taglist'>
<li><a href="/blog/tag/atomic/">atomic</a></li>
<li><a href="/blog/tag/centos/">centos</a></li>
<li><a href="/blog/tag/docker/">docker</a></li>
<li><a href="/blog/tag/kubernetes/">kubernetes</a></li>
<li><a href="/blog/tag/system-containers/">system containers</a></li>
</ul>
</div>

<p>
<small>Share this post:</small>
<span class='btn-group' id='social_share'>
<a class='btn btn-default btn-xs' href='http://twitter.com/share?text=yourtext&amp;url=http://www.projectatomic.io/blog/2016/09/running-kubernetes-in-containers-on-atomic/' role='button' title='Twitter'>
<i class='fa fa-twitter'></i>
Twitter
</a>
<a class='btn btn-default btn-xs' href='http://www.facebook.com/sharer.php?u=http://www.projectatomic.io/blog/2016/09/running-kubernetes-in-containers-on-atomic/' role='button' title='Facebook'>
<i class='fa fa-facebook'></i>
Facebook
</a>
<a class='btn btn-default btn-xs' href='https://plus.google.com/share?url=http://www.projectatomic.io/blog/2016/09/running-kubernetes-in-containers-on-atomic/' role='button' title='Google'>
<i class='fa fa-google-plus'></i>
Google+
</a>
</span>
</p>

</footer>
</article>

<section id='blog-comments'></section>
</div>
</section>

</section>
</div>
<div class='row'>
<div class='col-md-offset-3 col-md-9 col-lg-offset-2 col-lg-10' id='footer'>
<footer>
<hr class='visible-print'>
<ul class='footer-nav-list'>
<li><a target="_blank" href="https://fedoraproject.org/wiki/Legal:PrivacyPolicy">Privacy Policy</a></li>
</ul>

&copy; 2014&ndash;2021 Project Atomic. Sponsored by Red Hat, Inc.
        <script type="text/javascript">
        var _paq = _paq || [];
        _paq.push(['trackPageView']);
        _paq.push(['enableLinkTracking']);
        (function() {
        var u=(("https:" == document.location.protocol) ? "https" : "http") + "://tracker.osci.io/piwik/";
        _paq.push(['setTrackerUrl', u+'piwik.php']);
        _paq.push(['setSiteId', 4]);
        var d=document, g=d.createElement('script'), s=d.getElementsByTagName('script')[0]; g.type='text/javascript';
        g.defer=true; g.async=true; g.src=u+'piwik.js'; s.parentNode.insertBefore(g,s);
        })();
        </script>
<noscript><p><img src="https://tracker.osci.io/piwik/piwik.php?idsite=4" style="border:0;" alt="" /></p></noscript>
</footer>
</div>
</div>

</section>

<script src="/javascripts/application.js?1633620584" type="text/javascript"></script>


</body>
</html>
